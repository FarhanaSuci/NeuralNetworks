{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5193c8d2-65fa-4b5d-9698-a8dd1b4e71dc",
   "metadata": {},
   "source": [
    "**Exercise: Design the previous examples of neural network by adjusting weights and biases randomly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a9138e-ac04-4806-808c-3b54f32f7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.282857197797338\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "inputs=[1,2,3,2.5]\n",
    "weights=[]\n",
    "for i in range(len(inputs)):\n",
    "    weights.append(random.random())\n",
    "#print(weights)\n",
    "bias=random.randint(2,4)\n",
    "#print(bias)\n",
    "output_neuron=(inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2]+inputs[3]*weights[3]+bias)\n",
    "print(output_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574d01c-b727-4066-b53e-af90ccc296c9",
   "metadata": {},
   "source": [
    "**Exercise: A fully connected neural network â€” every neuron in the current layer has connections to every neuron from the previous layer. You have 4 input neurons, one hidden layer consisting of 3 neurons and one output neuron. You should adust weights and biases randomly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f2fef7-d90f-4217-ba0e-dbc8a44af2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer input weight is: \n",
      "[[0.7762501849081956, 0.6599051399984811, 0.06505014533369402, 0.9024473721905151], [0.7227290112759254, 0.567900416909339, 0.552670176036438, 0.2017164785089619], [0.3290779537583085, 0.13306107106344434, 0.23587603282579261, 0.48393964266392187]]\n",
      "Hidden layer neuron bias is: \n",
      "[5, -5, -4]\n",
      "Hidden layer is: \n",
      "[9.547329331382528, -0.9791684305236776, -1.4873226989776205]\n",
      "Hidden layer neuron weight is: \n",
      "[0.675817626795257, 0.06410321367189986, 0.4402967333869673]\n",
      "Output neuron is: \n",
      "8.734622281992916\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "inputs=[1,2,3,2.5]\n",
    "weights=[]\n",
    "rows,cols=3,4\n",
    "for i in range(rows):\n",
    "    col=[]\n",
    "    for k in range(cols):\n",
    "      col.append(random.random())\n",
    "    weights.append(col)\n",
    "hidden_layer=3\n",
    "bias=[]\n",
    "for j in range(hidden_layer):\n",
    "    bias.append(random.randint(-5,5))\n",
    "print(\"First layer input weight is: \")\n",
    "print(weights)\n",
    "print(\"Hidden layer neuron bias is: \")\n",
    "print(bias)\n",
    "layer_outputs=[]\n",
    "for neuron_weights,neuron_bias in zip(weights,bias):\n",
    "    neuron_output=0\n",
    "    for each_input,each_weight in zip(inputs,neuron_weights):\n",
    "        neuron_output+=each_input*each_weight\n",
    "    neuron_output+=neuron_bias\n",
    "    layer_outputs.append(neuron_output)\n",
    "print(\"Hidden layer is: \")\n",
    "print(layer_outputs)\n",
    "weights2=[]\n",
    "for i in range(3):\n",
    "    weights2.append(random.random())\n",
    "print(\"Hidden layer neuron weight is: \")\n",
    "print(weights2)\n",
    "bias2=random.randint(-5,5)\n",
    "output_neuron=(layer_outputs[0]*weights2[0]+layer_outputs[1]*weights2[1]+layer_outputs[2]*weights2[2]+bias2)\n",
    "print(\"Output neuron is: \") \n",
    "print(output_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcc1f5-567b-4718-9fd1-fd238cc4c2f2",
   "metadata": {},
   "source": [
    "**Exercise: take inputs containing 3 samples with 4 features, and 3 neurons with weights and biases, respectively. Then print the outputs of the neorons.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0703f648-056b-4b21-921a-df5d8e600e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8  -1.15  1.95]\n",
      " [ 6.85 -2.55  3.05]\n",
      " [ 5.8  -1.95  2.9 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "inputs=numpy.array([[1.0, 2.0, 3.0, 2.5],\n",
    "[2.0, 4.0, 1.5, 2.0],\n",
    "[0.5, 1.5, 2.0, 3.5]])\n",
    "weights=numpy.array([[0.2, 0.8, -0.5, 1.0],\n",
    "                    [0.5, -0.9, 0.3, -0.7],\n",
    "                    [-0.1, 0.6, -0.3, 0.9]])\n",
    "bias=numpy.array([2.0,1.0,-0.5])\n",
    "outputs=numpy.dot(inputs,weights.T)+bias\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00604b53-0586-4f7c-8585-3b886eba3b16",
   "metadata": {},
   "source": [
    "**Exercise: take inputs containing 3 samples with 4 features, and 3 neurons with weights and biases, respectively. Then print the outputs of the neorons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d562cde-046b-4f8c-89a5-9c62d6d40cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st input sample output neuron is:\n",
      "[4.8, -1.1500000000000004, 1.9500000000000002]\n",
      "2nd input sample output neuron is:\n",
      "[6.85, -2.5500000000000003, 3.05]\n",
      "3rd input sample output neuron is:\n",
      "[5.800000000000001, -1.9499999999999997, 2.9]\n",
      "Final outputs is : \n",
      "[[ 4.8  -1.15  1.95]\n",
      " [ 6.85 -2.55  3.05]\n",
      " [ 5.8  -1.95  2.9 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "inputs1=[1.0, 2.0, 3.0, 2.5]\n",
    "inputs2=[2.0, 4.0, 1.5, 2.0]\n",
    "inputs3=[0.5, 1.5, 2.0, 3.5]\n",
    "weights=[[0.2, 0.8, -0.5, 1.0],\n",
    "                    [0.5, -0.9, 0.3, -0.7],\n",
    "                    [-0.1, 0.6, -0.3, 0.9]]\n",
    "bias=[2.0,1.0,-0.5]\n",
    "outputs=[]\n",
    "sample_outputs=[]\n",
    "for neuron_bias,neuron_weights in zip(bias,weights):\n",
    "    neuron_output=0\n",
    "    for weight,each_input in zip(neuron_weights,inputs1):\n",
    "        neuron_output+=weight*each_input\n",
    "    neuron_output+=neuron_bias\n",
    "    sample_outputs.append(neuron_output)\n",
    "print(\"1st input sample output neuron is:\")\n",
    "print(sample_outputs)\n",
    "\n",
    "outputs.append(sample_outputs)\n",
    "sample_outputs=[]\n",
    "for neuron_bias,neuron_weights in zip(bias,weights):\n",
    "    neuron_output=0\n",
    "    for weight,each_input in zip(neuron_weights,inputs2):\n",
    "        neuron_output+=weight*each_input\n",
    "    neuron_output+=neuron_bias\n",
    "    sample_outputs.append(neuron_output)\n",
    "print(\"2nd input sample output neuron is:\")\n",
    "print(sample_outputs)\n",
    "\n",
    "outputs.append(sample_outputs)\n",
    "sample_outputs=[]\n",
    "for neuron_bias,neuron_weights in zip(bias,weights):\n",
    "    neuron_output=0\n",
    "    for weight,each_input in zip(neuron_weights,inputs3):\n",
    "        neuron_output+=weight*each_input\n",
    "    neuron_output+=neuron_bias\n",
    "    sample_outputs.append(neuron_output)\n",
    "print(\"3rd input sample output neuron is:\")\n",
    "print(sample_outputs)\n",
    "\n",
    "outputs.append(sample_outputs)\n",
    "output=numpy.array(outputs)\n",
    "print(\"Final outputs is : \")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b1a78-ce9a-4a37-afff-6510f3972e4e",
   "metadata": {},
   "source": [
    "**Exercise: take inputs containing 3 samples with 4 features, and 3 neurons with weights and biases, respectively. Then print the outputs of the neorons.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e34248-e6b7-4d01-a9a7-c9c4abb318fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample output  is:\n",
      "[4.8, -1.1500000000000004, 1.9500000000000002]\n",
      "sample output  is:\n",
      "[6.85, -2.5500000000000003, 3.05]\n",
      "sample output  is:\n",
      "[5.800000000000001, -1.9499999999999997, 2.9]\n",
      "           \n",
      "Final output is: \n",
      "[[ 4.8  -1.15  1.95]\n",
      " [ 6.85 -2.55  3.05]\n",
      " [ 5.8  -1.95  2.9 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "inputs=[[1.0, 2.0, 3.0, 2.5],\n",
    "      [2.0, 4.0, 1.5, 2.0],\n",
    "         [0.5, 1.5, 2.0, 3.5]]\n",
    "weights=[[0.2, 0.8, -0.5, 1.0],\n",
    "                    [0.5, -0.9, 0.3, -0.7],\n",
    "                    [-0.1, 0.6, -0.3, 0.9]]\n",
    "bias=[2.0,1.0,-0.5]\n",
    "outputs=[]\n",
    "\n",
    "for input_sample in inputs:\n",
    "   sample_outputs=[]\n",
    "   for neuron_bias,neuron_weights in zip(bias,weights):\n",
    "       neuron_output=0\n",
    "       for weight,each_input in zip(neuron_weights,input_sample):\n",
    "         neuron_output+=weight*each_input\n",
    "       neuron_output+=neuron_bias\n",
    "       sample_outputs.append(neuron_output)\n",
    "   print(\"sample output  is:\")\n",
    "   print(sample_outputs)\n",
    "   outputs.append(sample_outputs)\n",
    "print(\"           \")\n",
    "print(\"Final output is: \",end=\"\\n\") \n",
    "print(numpy.array(outputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f9902-5e5f-4891-8fb9-2eb09956a24e",
   "metadata": {},
   "source": [
    "**Exercise: Design the previous examples of neural network by adjusting weights and biases randomly.(Using AND gates)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63adcb14-1d0f-435c-b89e-16886eec7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs  [[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "Labels  [0 0 0 1]\n",
      "Random Biases  [-1.14113328]\n",
      "Random weights  [-2.15036115 -1.8563513 ]\n",
      "Predicted outputs  [0, 0, 0, 0]\n",
      "Correct predictions  3\n"
     ]
    }
   ],
   "source": [
    "#For 2 inputs and 1 output\n",
    "import numpy\n",
    "inputs=numpy.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "input_size=2\n",
    "output_size=1\n",
    "weight_size=2\n",
    "labels=numpy.array([0,0,0,1])\n",
    "weights=numpy.random.randn(input_size)\n",
    "bias=numpy.random.randn(output_size)\n",
    "def step_function(x):\n",
    "    return 0 if x<=0 else 1\n",
    "outputs=[]\n",
    "for input_row in inputs:\n",
    "    weighted_sum=numpy.dot(input_row,weights)+bias\n",
    "    output=step_function(weighted_sum)\n",
    "    outputs.append(output)\n",
    "correct_predictions=numpy.sum(outputs==labels)\n",
    "print(\"Inputs \",inputs)\n",
    "print(\"Labels \",labels)\n",
    "print(\"Random Biases \",bias)\n",
    "print(\"Random weights \",weights)\n",
    "print(\"Predicted outputs \",outputs)\n",
    "print(\"Correct predictions \",correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e47e6-c3a6-4135-befd-e58a50ec5826",
   "metadata": {},
   "source": [
    "**Exercise having 10 inputs samples with 4 features(without Activation Function)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc21745-ac1f-445e-9fd3-2b5832aeda85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Layer : \n",
      "\n",
      " [[-0.32165951  1.33369145  0.34127757  0.37837265]\n",
      " [-1.22878802  0.77137219 -1.24540942 -0.39899901]\n",
      " [-0.71256488 -1.21787593 -1.25656446 -0.56398334]\n",
      " [-0.25343714 -0.77600908  1.29931678  0.20122557]\n",
      " [ 0.33889547  1.27310803 -1.70209653  0.67417201]\n",
      " [-0.007058    0.87399007 -0.32070821  0.09338934]\n",
      " [-0.72701064 -0.67598497 -1.81077728 -0.67343286]\n",
      " [-0.31628949 -0.58966871  2.27133507  0.45722897]\n",
      " [ 1.26317293  1.64028411 -0.65087921  0.95204215]\n",
      " [-0.90933372 -0.29638723  1.10618283  0.82268802]]\n",
      "\n",
      "Weights1 :  \n",
      "\n",
      " [[ 0.3087094  -1.52041712  2.15695539  0.63807958]\n",
      " [ 0.27754603  0.875095   -1.81096181 -0.14084529]\n",
      " [ 0.70448106  1.36237655  0.72071794 -0.18799024]]\n",
      "\n",
      "Weights2 : \n",
      "\n",
      " [[-0.1491021   0.08685661 -0.11514357]\n",
      " [-0.61848288 -0.73816178 -0.26882781]\n",
      " [ 0.96565578  0.21554287 -0.43528517]]\n",
      "\n",
      "Weights3 : \n",
      "\n",
      " [[-1.05726517  1.49887143  0.25812449]]\n",
      "\n",
      "Bias1: \n",
      "\n",
      "  [1.68490619 0.73241281 1.24688067]\n",
      "\n",
      "Bias2: \n",
      "\n",
      "  [-0.05730336 -0.32113283  1.0561405 ]\n",
      "\n",
      "Bias3: \n",
      "\n",
      "  [1.13553672]\n",
      "\n",
      "Hidden layer:1 \n",
      "\n",
      " [[0.63073981 0.75747974 0.95311787]\n",
      " [0.05688667 0.96700915 0.64783613]\n",
      " [0.56128785 0.86103473 0.15265615]\n",
      " [0.99672283 0.08329753 0.71294591]\n",
      " [0.03269475 0.99281137 0.86606547]\n",
      " [0.43087903 0.88724613 0.8987958 ]\n",
      " [0.13619972 0.96487824 0.20347887]\n",
      " [0.9995358  0.01713939 0.85467482]\n",
      " [0.22873017 0.972429   0.97641719]\n",
      " [0.99155539 0.13028256 0.69953189]]\n",
      "\n",
      "Hidden layer:2 \n",
      "\n",
      " [[0.57457636 0.34976923 0.5902515 ]\n",
      " [0.49043187 0.2910346  0.62425259]\n",
      " [0.37142357 0.29420246 0.66676568]\n",
      " [0.6061185  0.46446563 0.64763206]\n",
      " [0.53994123 0.2964054  0.60072699]\n",
      " [0.54924793 0.32193133 0.59309591]\n",
      " [0.38275259 0.2733522  0.66652295]\n",
      " [0.64757231 0.48431787 0.6374736 ]\n",
      " [0.5621875  0.30818544 0.58500837]\n",
      " [0.59623049 0.45502187 0.64621659]]\n",
      "\n",
      "Output layer: \n",
      "\n",
      " [[0.76935533]\n",
      " [0.77107276]\n",
      " [0.7950964 ]\n",
      " [0.79544303]\n",
      " [0.76206088]\n",
      " [0.76682373]\n",
      " [0.78795316]\n",
      " [0.79271331]\n",
      " [0.76025732]\n",
      " [0.79478062]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "def sigmoid_function(x):\n",
    "    return 1 / (1 + numpy.exp(-x))\n",
    "\n",
    "inputs=numpy.random.randn(10,4)\n",
    "print(\"\\nInput Layer : \\n\\n\",inputs)\n",
    "input_size=4\n",
    "hidden_layer1_size=3\n",
    "hidden_layer2_size=3\n",
    "output_size=1\n",
    "weights1=numpy.random.randn(hidden_layer1_size,input_size)\n",
    "weights2=numpy.random.randn(hidden_layer2_size,hidden_layer1_size)\n",
    "weights3=numpy.random.randn(output_size,hidden_layer2_size)\n",
    "print(\"\\nWeights1 :  \\n\\n\",weights1)\n",
    "print(\"\\nWeights2 : \\n\\n\",weights2)\n",
    "print(\"\\nWeights3 : \\n\\n\",weights3)\n",
    "bias1=numpy.random.randn(hidden_layer1_size)\n",
    "bias2=numpy.random.randn(hidden_layer2_size)\n",
    "bias3=numpy.random.randn(output_size)\n",
    "print(\"\\nBias1: \\n\\n \",bias1)\n",
    "print(\"\\nBias2: \\n\\n \",bias2)\n",
    "print(\"\\nBias3: \\n\\n \",bias3)\n",
    "output1=[]\n",
    "for input_row in inputs:\n",
    "    weighted_sum = numpy.dot(input_row,numpy.array(weights1).T)+ bias1\n",
    "    output = sigmoid_function(weighted_sum)\n",
    "    output1.append(output)\n",
    "bias2=numpy.array(bias2)\n",
    "weights2=numpy.array(weights2)\n",
    "output2=[]\n",
    "for input_row in output1:\n",
    "    weighted_sum = numpy.dot(input_row,numpy.array(weights2))+ bias2\n",
    "    output = sigmoid_function(weighted_sum)\n",
    "    output2.append(output)\n",
    "print(\"\\nHidden layer:1 \\n\\n\",numpy.array(output1))\n",
    "print(\"\\nHidden layer:2 \\n\\n\",numpy.array(output2))\n",
    "output3=[]\n",
    "for input_row in output2:\n",
    "    weighted_sum = numpy.dot(input_row,numpy.array(weights3).T)+ bias3\n",
    "    output = sigmoid_function(weighted_sum)\n",
    "    output3.append(output)\n",
    "print(\"\\nOutput layer: \\n\\n\",numpy.array(output3))\n",
    "                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f324d64-6736-4964-9964-711ad03db8bf",
   "metadata": {},
   "source": [
    "**Exercise: Create a dataset using pandas for the following attributes and then predict the housing prices using neural network:\n",
    "Area: The total area of the house in square feet\n",
    "Bedrooms: The number of bedrooms in the house.\n",
    "Bathrooms: The number of bathrooms in the house.\n",
    "Age: The age of the house in years.\n",
    "Location: The neighborhood or area where the house is located.\n",
    "Garage Size: The size of the garage in square feet.\n",
    "Yard Size: The size of the yard or outdoor space in square feet.\n",
    "Amenities: A binary feature indicating whether the house has additional amenities such as a swimming pool, gym, etc.\n",
    "School Rating: The rating of nearby schools, on a scale from 1 to 10.\n",
    "Distance to City Center: The distance of the house from the city center in miles.\n",
    "Price: The selling price of the house.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12da7d3-2d70-48f4-9e93-c202b3d52c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Garage Size</th>\n",
       "      <th>Yard Size</th>\n",
       "      <th>Amenities</th>\n",
       "      <th>School Rating</th>\n",
       "      <th>Distance to City Center</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Urban</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Rural</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2200</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>450</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Urban</td>\n",
       "      <td>350</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2800</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Rural</td>\n",
       "      <td>600</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2100</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Urban</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18</td>\n",
       "      <td>Rural</td>\n",
       "      <td>550</td>\n",
       "      <td>1100</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  Bedrooms  Bathrooms  Age  Location  Garage Size  Yard Size  \\\n",
       "0  2000         3        2.0   10  Suburban          400        800   \n",
       "1  1800         2        1.5    5     Urban          300        600   \n",
       "2  2500         4        3.0   15     Rural          500       1000   \n",
       "3  2200         3        2.5    8  Suburban          450        900   \n",
       "4  1900         2        2.0    3     Urban          350        700   \n",
       "5  2800         5        3.5   20     Rural          600       1200   \n",
       "6  2100         4        2.5   12  Suburban          400        800   \n",
       "7  1700         2        1.0    6     Urban          250        500   \n",
       "8  2400         3        3.0   18     Rural          550       1100   \n",
       "9  2000         3        2.0    9  Suburban          400        800   \n",
       "\n",
       "   Amenities  School Rating  Distance to City Center   Price  \n",
       "0          1              8                        5  300000  \n",
       "1          0              7                        2  250000  \n",
       "2          1              6                       10  350000  \n",
       "3          1              9                        7  320000  \n",
       "4          0              8                        4  280000  \n",
       "5          1              5                       15  400000  \n",
       "6          1              7                        6  310000  \n",
       "7          0              6                        3  240000  \n",
       "8          1              4                       12  370000  \n",
       "9          1              8                        5  300000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "data={\n",
    "    'Area':[2000, 1800, 2500, 2200, 1900, 2800, 2100, 1700, 2400, 2000],\n",
    "    'Bedrooms':[3, 2, 4, 3, 2, 5, 4, 2, 3, 3],\n",
    "    'Bathrooms':[2, 1.5, 3, 2.5, 2, 3.5, 2.5, 1, 3, 2],\n",
    "    'Age':[10, 5, 15, 8, 3, 20, 12, 6, 18, 9],\n",
    "    'Location':['Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban', 'Urban', 'Rural', 'Suburban'],\n",
    "    'Garage Size':[400, 300, 500, 450, 350, 600, 400, 250, 550, 400],\n",
    "    'Yard Size':[800, 600, 1000, 900, 700, 1200, 800, 500, 1100, 800],\n",
    "    'Amenities':[1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "    'School Rating':[8, 7, 6, 9, 8, 5, 7, 6, 4, 8],\n",
    "    'Distance to City Center':[5, 2, 10, 7, 4, 15, 6, 3, 12, 5],\n",
    "    'Price':[300000, 250000, 350000, 320000, 280000, 400000, 310000, 240000, 370000, 300000]\n",
    "}\n",
    "df=pandas.DataFrame(data)\n",
    "df\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4785d9e-a7a1-4cc2-945e-05fd12ed7e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Age</th>\n",
       "      <th>Location</th>\n",
       "      <th>Garage Size</th>\n",
       "      <th>Yard Size</th>\n",
       "      <th>Amenities</th>\n",
       "      <th>School Rating</th>\n",
       "      <th>Distance to City Center</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Urban</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Rural</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2200</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>450</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Urban</td>\n",
       "      <td>350</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  Bedrooms  Bathrooms  Age  Location  Garage Size  Yard Size  \\\n",
       "0  2000         3        2.0   10  Suburban          400        800   \n",
       "1  1800         2        1.5    5     Urban          300        600   \n",
       "2  2500         4        3.0   15     Rural          500       1000   \n",
       "3  2200         3        2.5    8  Suburban          450        900   \n",
       "4  1900         2        2.0    3     Urban          350        700   \n",
       "\n",
       "   Amenities  School Rating  Distance to City Center   Price  \n",
       "0          1              8                        5  300000  \n",
       "1          0              7                        2  250000  \n",
       "2          1              6                       10  350000  \n",
       "3          1              9                        7  320000  \n",
       "4          0              8                        4  280000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5148996-35d9-4271-b902-7260a5830fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd21171-dc73-4742-94b8-fa99b5345523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2000, 3, 2.0, 10, 'Suburban', 400, 800, 1, 8, 5, 300000],\n",
       "       [1800, 2, 1.5, 5, 'Urban', 300, 600, 0, 7, 2, 250000],\n",
       "       [2500, 4, 3.0, 15, 'Rural', 500, 1000, 1, 6, 10, 350000],\n",
       "       [2200, 3, 2.5, 8, 'Suburban', 450, 900, 1, 9, 7, 320000],\n",
       "       [1900, 2, 2.0, 3, 'Urban', 350, 700, 0, 8, 4, 280000],\n",
       "       [2800, 5, 3.5, 20, 'Rural', 600, 1200, 1, 5, 15, 400000],\n",
       "       [2100, 4, 2.5, 12, 'Suburban', 400, 800, 1, 7, 6, 310000],\n",
       "       [1700, 2, 1.0, 6, 'Urban', 250, 500, 0, 6, 3, 240000],\n",
       "       [2400, 3, 3.0, 18, 'Rural', 550, 1100, 1, 4, 12, 370000],\n",
       "       [2000, 3, 2.0, 9, 'Suburban', 400, 800, 1, 8, 5, 300000]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f9b179-a258-4d31-af30-245557976a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23142d6b-252a-4517-8db2-bfa5c0fb932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "104f601e-7287-40d4-bb97-76c9a5e91e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d12158e-2efd-4908-b3ab-afbf1bfec070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1119dcc-be36-47c4-8163-b4830ca7d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0        8450            7            5          856         2         1   \n",
       "1        9600            6            8         1262         2         0   \n",
       "2       11250            7            5          920         2         1   \n",
       "3        9550            7            5          756         1         0   \n",
       "4       14260            8            5         1145         2         1   \n",
       "...       ...          ...          ...          ...       ...       ...   \n",
       "1455     7917            6            5          953         2         1   \n",
       "1456    13175            6            6         1542         2         0   \n",
       "1457     9042            7            9         1152         2         0   \n",
       "1458     9717            5            6         1078         1         0   \n",
       "1459     9937            5            6         1256         1         1   \n",
       "\n",
       "      BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0                3             8           0         548                 1  \n",
       "1                3             6           1         460                 1  \n",
       "2                3             6           1         608                 1  \n",
       "3                3             7           1         642                 0  \n",
       "4                4             9           1         836                 1  \n",
       "...            ...           ...         ...         ...               ...  \n",
       "1455             3             7           1         460                 1  \n",
       "1456             3             7           2         500                 1  \n",
       "1457             4             9           2         252                 1  \n",
       "1458             2             5           0         240                 0  \n",
       "1459             3             6           0         276                 0  \n",
       "\n",
       "[1460 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housepricedata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f568a07-ee99-4ca9-bf91-f3950dda3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e81dc2bc-f6b0-4964-b0d6-88e9a94fb89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8450,     7,     5, ...,     0,   548,     1],\n",
       "       [ 9600,     6,     8, ...,     1,   460,     1],\n",
       "       [11250,     7,     5, ...,     1,   608,     1],\n",
       "       ...,\n",
       "       [ 9042,     7,     9, ...,     2,   252,     1],\n",
       "       [ 9717,     5,     6, ...,     0,   240,     0],\n",
       "       [ 9937,     5,     6, ...,     0,   276,     0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2e3d72d-ebd1-4e84-a74a-ded337c145f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8626ab93-868e-4ae5-a1e2-11504a927937",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a661fd50-74e5-4afe-87db-07bdfc391114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94a55f18-8c98-4170-a517-49a26cec5a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0334198 , 0.66666667, 0.5       , ..., 0.5       , 0.        ,\n",
       "        0.3864598 ],\n",
       "       [0.03879502, 0.55555556, 0.875     , ..., 0.33333333, 0.33333333,\n",
       "        0.32440056],\n",
       "       [0.04650728, 0.66666667, 0.5       , ..., 0.33333333, 0.33333333,\n",
       "        0.42877292],\n",
       "       ...,\n",
       "       [0.03618687, 0.66666667, 1.        , ..., 0.58333333, 0.66666667,\n",
       "        0.17771509],\n",
       "       [0.03934189, 0.44444444, 0.625     , ..., 0.25      , 0.        ,\n",
       "        0.16925247],\n",
       "       [0.04037019, 0.44444444, 0.625     , ..., 0.33333333, 0.        ,\n",
       "        0.19464034]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5edc4b06-b4c2-4254-84cf-97316b5f2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7875df0b-e475-4937-ac66-d3d027245215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e65af3c-cc15-48e2-a0ad-b3ed7fc4c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e14b6634-67a8-4ecd-b10c-d2b1fd858b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4f6071-bab8-4f7c-94dc-1d7d273d03ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights found, iteration: 0 loss: 0.17975749783268022\n",
      "New weights found, iteration: 1 loss: 0.1482529143940371\n",
      "New weights found, iteration: 2 loss: 0.1310379070940262\n",
      "New weights found, iteration: 3 loss: 0.1254916216384162\n",
      "New weights found, iteration: 4 loss: 0.1127959004497159\n",
      "New weights found, iteration: 7 loss: 0.09947259438111225\n",
      "New weights found, iteration: 11 loss: 0.09113513937864623\n",
      "New weights found, iteration: 13 loss: 0.08380984500279856\n",
      "New weights found, iteration: 14 loss: 0.07485265948950344\n",
      "New weights found, iteration: 15 loss: 0.0744217397393336\n",
      "New weights found, iteration: 18 loss: 0.07241928941971147\n",
      "New weights found, iteration: 25 loss: 0.06591645542410444\n",
      "New weights found, iteration: 28 loss: 0.0520628438958379\n",
      "New weights found, iteration: 30 loss: 0.04724992237902982\n",
      "New weights found, iteration: 35 loss: 0.04152636821206253\n",
      "New weights found, iteration: 36 loss: 0.0367507705539059\n",
      "New weights found, iteration: 40 loss: 0.035821297080322\n",
      "New weights found, iteration: 43 loss: 0.03162920713736289\n",
      "New weights found, iteration: 46 loss: 0.026575275693009583\n",
      "New weights found, iteration: 48 loss: 0.025459343853687876\n",
      "New weights found, iteration: 49 loss: 0.022507737449843745\n",
      "New weights found, iteration: 50 loss: 0.01974439688859492\n",
      "New weights found, iteration: 51 loss: 0.014971892790609238\n",
      "New weights found, iteration: 52 loss: 0.012799165340579592\n",
      "New weights found, iteration: 53 loss: 0.011629576845760445\n",
      "New weights found, iteration: 55 loss: 0.010233293673446017\n",
      "New weights found, iteration: 58 loss: 0.009022507757810615\n",
      "New weights found, iteration: 62 loss: 0.0079174132400378\n",
      "New weights found, iteration: 82 loss: 0.007671778049676468\n",
      "New weights found, iteration: 83 loss: 0.006665478569901491\n",
      "New weights found, iteration: 85 loss: 0.0066160854079032865\n",
      "New weights found, iteration: 86 loss: 0.004575998457350749\n",
      "New weights found, iteration: 91 loss: 0.0032093779793033756\n",
      "New weights found, iteration: 92 loss: 0.0029143825570351646\n",
      "New weights found, iteration: 93 loss: 0.0025163776992530827\n",
      "New weights found, iteration: 95 loss: 0.0019529377238351091\n",
      "New weights found, iteration: 98 loss: 0.0012765328819054607\n",
      "New weights found, iteration: 101 loss: 0.0009871539249921612\n",
      "New weights found, iteration: 105 loss: 0.0008706450779186232\n",
      "New weights found, iteration: 107 loss: 0.0007826941304593736\n",
      "New weights found, iteration: 112 loss: 0.0006760787772437849\n",
      "New weights found, iteration: 113 loss: 0.0005293311706809497\n",
      "New weights found, iteration: 116 loss: 0.0005187370720893722\n",
      "New weights found, iteration: 118 loss: 0.0005129584814802344\n",
      "New weights found, iteration: 120 loss: 0.00041641707149575683\n",
      "New weights found, iteration: 126 loss: 0.00041531741129618115\n",
      "New weights found, iteration: 129 loss: 0.00031664088500403564\n",
      "New weights found, iteration: 139 loss: 0.0002982506402490812\n",
      "New weights found, iteration: 142 loss: 0.0002934999467898224\n",
      "New weights found, iteration: 148 loss: 0.00022140638576963423\n",
      "[[1.04168941e-05]\n",
      " [3.81103757e-02]\n",
      " [2.17208287e-02]\n",
      " [9.88296961e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')#initially zero\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "for iteration in range(150):\n",
    "    # Forward pass\n",
    "    hidden_layer_output = np.dot(x, W1) + b1\n",
    "    output = sigmoid(np.dot(hidden_layer_output, W2) + b2)\n",
    "\n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, hidden_size)\n",
    "    b1 += 0.09 * np.random.randn(hidden_size)\n",
    "    W2 += 0.09 * np.random.randn(hidden_size, output_size)\n",
    "    b2 += 0.09 * np.random.randn(output_size)\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bcac292-afdf-479c-94de-2dbc9a4e84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "[[0.89013246]\n",
      " [0.81529945]\n",
      " [0.95064447]\n",
      " [0.91299899]]\n",
      "Loss: 0.5920857668994902\n"
     ]
    }
   ],
   "source": [
    "# Solve the and gate problem and then calculate the loss uisng mean square error.\n",
    "# run several times of the code and compare the error. Is the result same in every case? If so, why?\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# Forward pass\n",
    "hidden_layer_output = (np.dot(x, W1) + b1)\n",
    "output = sigmoid(np.dot(hidden_layer_output, W2) + b2)\n",
    "\n",
    "# Calculate the loss (using Mean Squared Error)\n",
    "loss = np.mean((output - target) ** 2)\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cc61ed-da7f-404e-94d2-abaa11a5d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "[[0.49543945]\n",
      " [0.98975634]\n",
      " [0.84499765]\n",
      " [0.99813929]]\n",
      "Loss: 0.4847755843369881\n"
     ]
    }
   ],
   "source": [
    "# Solve the and gate problem and then calculate the loss uisng mean square error.\n",
    "# run several times of the code and compare the error. Is the result same in every case? If so, why?\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# Forward pass\n",
    "hidden_layer_output = (np.dot(x, W1) + b1)\n",
    "output = sigmoid(np.dot(hidden_layer_output, W2) + b2)\n",
    "\n",
    "# Calculate the loss (using Mean Squared Error)\n",
    "loss = np.mean((output - target) ** 2)\n",
    "\n",
    "print(\"Output:\")\n",
    "print(output)\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0d218d-367a-4e0d-877c-5dea10cf3928",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(best_loss\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     hidden_layer_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x, W1) \u001b[38;5;241m+\u001b[39m b1\n\u001b[1;32m---> 41\u001b[0m     output \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b2)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# save final output\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     final_output\u001b[38;5;241m=\u001b[39moutput\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,1) and (3,1) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "#hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "iteration=0\n",
    "\n",
    "while(best_loss>=0.05):\n",
    "    # Forward pass\n",
    "    hidden_layer_output = np.dot(x, W1) + b1\n",
    "    output = sigmoid(np.dot(hidden_layer_output, W2) + b2)\n",
    "\n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration=iteration+1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, hidden_size)\n",
    "    b1 += 0.09 * np.random.randn(hidden_size)\n",
    "    W2 += 0.09 * np.random.randn(hidden_size, output_size)\n",
    "    b2 += 0.09 * np.random.randn(output_size)\n",
    "\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a3938-9823-48f3-8110-43c0679e10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "#hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "iteration=0\n",
    "\n",
    "while(best_loss>=0.05):\n",
    "    # Forward pass\n",
    "    output = np.dot(x, W1) + b1\n",
    "    \n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration=iteration+1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, output_size)\n",
    "    b1 += 0.09 * np.random.randn(output_size)\n",
    "print(final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549194e5-f04f-4e46-ad13-79f5e9156558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "#hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "iteration=0\n",
    "\n",
    "while(best_loss>=0.05):\n",
    "    # Forward pass\n",
    "    output = np.dot(x, W1) + b1\n",
    "    \n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration=iteration+1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, output_size)\n",
    "    b1 += 0.09 * np.random.randn(output_size)\n",
    "print(final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f4a11-a70f-407d-a86d-05622df7ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Use sigmoidal activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Creating loss function\n",
    "def loss(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "#hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(input_size, output_size)\n",
    "b1 = np.random.randn(output_size)\n",
    "\n",
    "# Define the input for the AND gate\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "# Define the target output for the AND gate\n",
    "target = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# final_output\n",
    "final_output=None\n",
    "\n",
    "# Create some variables to track the best loss and the associated weights and biases\n",
    "best_loss = float('inf')\n",
    "best_W1 = None\n",
    "best_b1 = None\n",
    "best_W2 = None\n",
    "best_b2 = None\n",
    "\n",
    "iteration=0\n",
    "\n",
    "while(best_loss>=0.05):\n",
    "    # Forward pass\n",
    "    output = np.dot(x, W1) + b1\n",
    "    \n",
    "    # save final output\n",
    "    final_output=output\n",
    "\n",
    "    # Loss calculation\n",
    "    current_loss = loss(output, target)\n",
    "\n",
    "    iteration=iteration+1\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        print('New weights found, iteration:', iteration, 'loss:', current_loss)\n",
    "        # Save current weights and biases as the best ones so far\n",
    "        best_loss = current_loss\n",
    "        best_W1 = W1.copy()\n",
    "        best_b1 = b1.copy()\n",
    "        best_W2 = W2.copy()\n",
    "        best_b2 = b2.copy()\n",
    "    else:\n",
    "        # Revert weights and biases to the previous best values\n",
    "        W1 = best_W1.copy()\n",
    "        b1 = best_b1.copy()\n",
    "        W2 = best_W2.copy()\n",
    "        b2 = best_b2.copy()\n",
    "\n",
    "    # Update weights with small random values\n",
    "    W1 += 0.09 * np.random.randn(input_size, output_size)\n",
    "    b1 += 0.09 * np.random.randn(output_size)\n",
    "print(final_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95507f-e9ee-4acc-a5e1-5178f6ea3a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
